\documentclass[conference]{IEEEtran}

\usepackage{amssymb,amsmath}
\usepackage{graphicx}
\usepackage[usenames,dvipsnames]{pstricks}
\usepackage{epsfig}
\usepackage{booktabs}
\usepackage{pst-grad} % For gradients
\usepackage{pst-plot} % For axes
\usepackage{url}

\newcommand{\eat}[1]{}

\topmargin = -1.5cm
\textheight = 24cm

\title{Exploiting Data Parallelism in SELinux Using a Multicore Processor}

\author{
    \IEEEauthorblockN{Arun Kalyanasundaram\IEEEauthorrefmark{1}\IEEEauthorrefmark{3},
      Bodhisatta Barman Roy\IEEEauthorrefmark{2}\IEEEauthorrefmark{5}, Shrisha Rao\IEEEauthorrefmark{1}\IEEEauthorrefmark{4}}
    \IEEEauthorblockA{\IEEEauthorrefmark{1}International Institute of
      Information Technology Bangalore, India
    \\\IEEEauthorrefmark{3}arun.k@iiitb.net, \IEEEauthorrefmark{4}shrao@ieee.org}
    \IEEEauthorblockA{\IEEEauthorrefmark{2}National University of
      Singapore, Singapore
    \\\IEEEauthorrefmark{5}bodhi@comp.nus.edu.sg}
}

\pagestyle{empty}

\begin{document}

\maketitle
\begin{abstract}

Security Enhanced Linux, popularly known as SELinux~\cite{s1}, is a
Linux operating system feature that provides fine-grained access
control over system resources.  Our goal is to optimize the
performance of SELinux for a multicore processor and analyze the
efficacy of our approach.  We study the architecture of SELinux to
identify specific components that cause performance bottlenecks, and
empirically validate our claims.  We propose various techniques to
delegate processor-intensive computations to multiple cores.  We
perform several experiments to evaluate the performance of our
approach under different conditions, and discuss the intricacies of
our implementation.  Our results show that software applications with
security validations have an inherent data parallelism which can be
exploited for concurrent execution, but the gain in efficiency depends
on design of the application and the hardware platform.  In addition,
we find that the gain in efficiency is also influenced by the
optimization technique and the system configuration.  We use a Cell
Broadband Engine (CBE) processor running SELinux for our experiments,
but our approach can be easily adapted to applications with a similar
security validation framework running on other multicore platforms.

\end{abstract}

{\bf Keywords:} Parallel Algorithms, Security, Operating Systems,
Security Enhanced Linux, Cell Broadband Engine

\thispagestyle{empty}

\section{Introduction}\label{intro}

SELinux is a Linux operating system feature that implements the
Mandatory Access Control (MAC) security paradigm.  MAC operates on a
set of rules to constrain a `process' from performing a particular
operation on a resource (e.g. file, directory, etc). These rules form the
security policy of a system and is centrally controlled by an
administrator.  Each resource and process is assigned a
label called the \emph{security context} (SC). Thus a rule simply
states if one SC is allowed to perform an operation on another SC.

One of the major drawbacks of SELinux is the performance overhead
associated with it. The system performance reduces by about 7\% when
SELinux is enabled and in certain cases like networked systems, the
overhead may be much higher~\cite{selinuxFAQ}.  In addition, the worst
case performance could be unacceptably low depending on the number of
rules in the security policy~\cite{report}.  Our goal is to optimize
the performance of SELinux for a multicore processors and analyze the
effectiveness of our approach.

In this paper, we first study the architecture of SELinux to determine
the scope for introducing data parallelism.  We pin-point the specific
components within SELinux that cause performance bottlenecks and
empirically validate our claims.  Based on our analysis, we propose
various techniques to modify the SELinux architecture for parallel
execution.  Our work takes a high-level approach so that our proposed
techniques can also be applied to other large-scale security
software.  More specifically, we optimize the general process of
security validations, which involves verifying the credibility of a
given entity against a set of trusted entities.  We perform several
experiments to evaluate the performance of our approach under
different conditions.  For our experiments, we use the Cell Broadband
Engine (CBE) multicore processor since it is known to outperform
single-core processors by almost an order of magnitude~\cite{CBEArch}.

%Sections organized
The rest of the paper is organized as follows.  In
Section~\ref{background}, we discuss the background and state of art
related to our work.  In Section~\ref{design}, we study the
architecture of SELinux to identify performance bottlenecks and
propose various techniques to achieve data parallelism.  In
Section~\ref{expr}, we discuss our experimental setup,
intricacies/challenges of our implementation, results and inferences.
We conclude with a view for future work, in Section~\ref{conclusion}.

\section{Background and Related Work}\label{background}

Security has been an integral part of every software application and a
primary focus of networking and operating systems research.  With the
advent of cloud computing, security has gained prominence like never
before, since these applications can now be accessible from anywhere
in the world and are thus even more vulnerable than their stand-alone
counterparts.  However, security comes with a steep price in the form
of loss in efficiency.  Even so, when it comes to building a security
feature, efficiency is often given less importance than robustness, a
trend that has led to significant performance losses in modern-day
systems, where even an anti-virus application can slow down the system
by more than fifty percent.  This applies even to operating systems'
inbuilt security features like SELinux~\cite{s1}, RSBAC~\cite{s2},
TOMOYO Linux\footnote{http://tomoyo.sourceforge.jp}, and
AppArmor\footnote{http://wiki.apparmor.net}.

With processor clock speeds reaching saturation, extensive research is
underway in optimizing existing software applications for multicore
processors.  Our work aims to exploit data parallelism in SELinux to
optimize its performance for multicore processors.  There has not been
any sizeable effort in optimizing the performance of SELinux
\cite{selinuxFAQ}.  Though there has been some work on optimizing
SELinux for 32 or more processors, no further details exist
\cite{selinuxFAQ}.  There have been attempts to extend the SELinux
functionality to a distributed setting~\cite{tresys}.  Brindle
\emph{et al.}~\cite{tresys} present a distributed policy-management
architecture and address several challenges like synchronization of
policy updates, managing multi-system policy, etc.  In our work, we
focus on optimizing SELinux for a single system with multiple
processors (or cores), rather than an inter-connected distributed
system, which could be a scope for future work.  The multicore
optimization is also based on implementing parallelized
data-structures~\cite{ll1}.

SELinux is based on the Flux Advanced Security Kernel (Flask)
architecture~\cite{flask}.  It consists of two major components, the
\emph{Object Manager} which enforces security policy decisions and the
\emph{Security Server} which provides security decisions.  The Object
Manager is responsible for labeling the resources and respond to
changes in the security policy~\cite{flask}. Every access permission
request has to be authorized by the Object Manager, and these requests
are managed by the Linux Security Module (LSM) framework
\cite{selinuxBook}.  LSM consists of a set of hooks at specific points
in the kernel where access to a resource is from a system call.  These
hooks are a set of function pointers which by default do nothing,
unless overridden by a security module like SELinux.  The return
values of these hooks determine whether an access is granted or
denied.

When the Object Manager receives a request from the LSM, it extracts
the security context of the source and target, to invoke the Security
Server with these parameters.  The Security Server makes the decision
to grant/deny the requested operation based on the rules specified in
the security policy.  The Object Manager caches recently computed 
access decisions in a data structure called the Access Vector Cache
(AVC).  The AVC is a simple hash-table implementation
using \emph{open addressing}. The Object Manager can bypass the Security Server when a requested
access decision is available in AVC. Since the
decision-making logic of the Security Server is extremely
processor-intensive, the use of AVC can considerably improve the performance. 

We evaluate the performance of SELinux using a CBE multicore processor
which consists of one Power Processing Element (PPE) and eight
Synergistic Processing Elements (SPE)~\cite{CBEArch}.  The SPEs are
designed specifically to perform processor-intensive computations.  A
SPE by itself cannot initiate a computation, only a PPE can initialize
an SPE by loading the desired executable binary into the SPEs' local
cache.  In addition, data required by an SPE during execution requires
the use of Direct Memory Access (DMA) controllers.  At the time of SPE
initialization, the PPE sends an address of a location in main memory
which the SPE can use as a base address to read/write data.  In order
to access contents of the main memory, the SPE makes a DMA request
with the base address, the number of bytes, and the type of access
(read or write).  Each SPE has one or more dedicated DMA engines that
perform data transfers to and from main memory to SPEs' local caches,
concurrent with program execution.  In our implementation we also use
the CBE SDK which provides flexible APIs which can perform both
asynchronous and synchronous DMA requests.

Performing large-scale experiments using SELinux requires the creation
of many security policies with different configurations, but creation
of policies is a hard and tedious process.  In general, it is a job of
system administrators to write these policies, which typically contain
thousands of rules.  Another issue with manual maintenance of large
security policies is the detection of loopholes which could lead to
possible security breaches.  Several tools have been developed to
automate the process of SELinux policy
configuration~\cite{selinuxTools}.  While these tools mainly provide
effective analysis of security policies~\cite{selinuxTools}, policy
creation is still a manual process.  Therefore, we implement a set of
Unix shell-scripts to automatically generate SELinux security policies
with a specific access permission patterns
\footnote{http://selinuxoncbe.svn.sourceforge.net/viewvc/selinuxoncbe/trunk/src/policies/scripts/}.

\section{Design}\label{design}

In SELinux access control, a process can perform an operation
(e.g. read, write) on a resource (e.g., files, directories, ports)
only when the corresponding rule is specified in the policy.  A rule
simply states if a security context can perform a particular operation
on another security context.  Each process and resource on the system
are associated with a security context, and the decision to allow or
disallow an operation is based on the following,

\begin{itemize}

\item The validity of the security contexts of source (process) and
  target (resource).
\item The presence of a rule in the policy that allows the requested
  operation.

\end{itemize}

A security context is considered valid if all of its three components
(user, role and type) are valid.  The validation is performed by
extracting each component and matching it against a \emph{list of
  valid contexts}.  We will show in Section~\ref{results} that the
validation step is the major cause for performance overhead in
SELinux.  We therefore model this step for parallel execution using the
SIMD (Single Instruction Multiple Dataset) programming
paradigm.  Specifically, we look at exploiting data parallelism by
dedicating one or more processing units to the matching operation of
each component of the security context.  We use the principle of SIMD
because each processing unit operates on a different data but executes
the same set of instructions.  Since the security context has three
components, we can use a minimum of three processing units considering
each component requires one dedicated unit.  We propose the following
techniques based on the number of processing units and its loading
strategy, and compare their relative performances (runtimes).

\begin{itemize}

\item \textbf{Three Processing Units ($3U$)}: In this technique we use
  one dedicated processing unit for each component of the security
  context, hence a total of three units.  In the CBE processor, these
  processing units are the Synergistic Processing Elements (SPEs),
  which operate in slave mode (Section~\ref{background}).  Each SPE
  performs a linear search on the list of valid contexts corresponding
  to each component of the security context, as shown in
  Figure~\ref{figOneSPE}.  The dashed line in Figure~\ref{figOneSPE}
  shows the direction of traversal.

\item \textbf{Three Processing Units with Busy Wait ($3UBW$)}: In
  general, SPEs are initialized with a set of instructions and a base
  address of the required data in main memory.  To access this data,
  the SPE has to make DMA requests and wait until the data is received
  (Section~\ref{background}).  However, when the data is not stored in
  consecutive chunks of memory (e.g., a linked list), the SPE is
  initialized every time with the address of the next chunk of data,
  which is the approach we use in $3U$ (mentioned above).  But we
  observe that the frequent initialization of SPE has a significant
  performance overhead.  Therefore we devise a busy wait technique, in
  which the SPE is initialized with the address of a unique location
  in main memory\eat{ instead of the base address of the data}.  This
  location is updated with the base address of the next chunk of data,
  every time, after the SPE reads it.  The details of the implementation
  are given in Section~\ref{impl}.

\item \textbf{Six Processing Units ($6U$)}: This technique is similar
  to $3U$, except that two dedicated SPEs per component of the
  security context are used, instead of just one.  Thus a total of six
  processing units are used in this technique.  Since two SPEs operate
  on the list simultaneously, each SPE can process either the odd- or
  the even-numbered elements of the list, as shown in
  Figure~\ref{figTwoSPE}.

\item \textbf{Six Processing Units with Busy Wait ($6UBW$)}: In this
  we use six processing units using the same design as given in $6U$,
  with each SPE operating in the busy wait mode as described in
  $3UBW$.

\end{itemize}

\begin{figure}
\includegraphics[scale=0.45]{images/oneSPE.png}
\caption{Traversing a linked list using one SPE.}
\label{figOneSPE}
\vspace{0.05cm}
\end{figure}


\begin{figure}
\includegraphics[scale=0.45]{images/twoSPE.png}
\caption{Traversing a linked list using two SPEs.}
\label{figTwoSPE}
\vspace{0.05cm}
\end{figure}

\section{Experiments}\label{expr}

The goal of our experiments was to evaluate the performances of the
different techniques proposed in Section~\ref{design} on a CBE
processor.  For this purpose we used the \emph{Sony Play Station 3}
(PS3) with \emph{Yellow Dog Linux 6.1} (for PowerPC architecture)
installed.  The PS3 has eight SPEs, of which six are accessible to
a programmer.  SELinux is a part of the security module of the mainline
Linux kernel since version 2.6, but the default installation of
YDL does not contain SELinux.  Therefore in our setup, we recompiled the
Linux kernel (version 2.6.27) for the PowerPC architecture with the
necessary configurations (file-system extended attribute support,
security hooks, etc.) to enable SELinux~\cite{report}.

We used our experimental setup to study the impact of the following two
configurable parameters: (1) the number of valid security contexts;
and (2) the maximum size of the Access Vector Cache (AVC).  The number of
valid security contexts is determined by the number of rules in the
policy configuration file. Although, AVC significantly improves the performance of SELinux, it also prevents us from accurately measuring the overhead due to the decision-making logic in Security Server (see Section~\ref{background}). Therefore, we run our experiments with two different maximum size of AVC: (a) 512 entries (\emph{optimal}); and (b) 1 entry (\emph{minimal}). Since the AVC is a hash-table with a fixed number of buckets, a larger size could imply longer chain lengths and hence poorer performance. It has been found through extensive optimization benchmarking that a maximum size of AVC with 512 entries is optimal to maintain smaller chain lengths~\cite{selinuxBook}. Ideally, in our experiments the \emph{minimal} size of AVC should be zero, however the normal functioning of SELinux requires the size of AVC to be at least one entry.

Broadly, our experiments can be divided into two phases.  In the first
phase, we evaluate the performance of SELinux using only the single
core (PPE) of the CBE processor.  This involves measuring the
performance with different numbers of rules in the policy
configuration file.  We use this to establish a performance benchmark
and to show that the security context validation step is indeed highly
processor-intensive.  In the second phase, we compare the performance
of the SIMD techniques proposed in Section~\ref{design} with the
single-core performance.  In each phase, the experiments are performed
with both \emph{optimal} and \emph{minimal} values of maximum AVC size.

\subsection{Implementation Details}\label{impl}

%Since the CBE SDK (version 3.1) does not support kernel space libraries, we perform our experiments using only the SELinux user space libraries.
In SELinux, the process of associating a security context to a
resource on the file system is called \emph{labeling}.  When the
system boots with SELinux enabled, the labeling of the file system
takes place based on the settings in $file\textunderscore contexts$
\cite{selinuxBook}.  Once labeled, the security context cannot be
changed without authorization.  However, malicious programs can
sometimes take advantage of weak policy configurations to modify the
security contexts of certain files.  This could be a significant
security breach and may allow undesirable processes to access
protected files.  Therefore, SELinux provides a functionality to
re-label the file-system, which allows us to restore the original
security context on system resources without having to reboot the
system.  The re-labeling process validates the security context of the
resource being labeled against a list of valid contexts.  This is the
same operation that is performed by the security server of SELinux to
make access decisions.  Hence, in our experiments we evaluate the
performance of this re-labeling process to capture the overhead due to
security validations in SELinux.  The SELinux user-space libraries
(\emph{setfiles}, \emph{libselinux} and \emph{libselpol}) are modified
appropriately to incorporate the proposed SIMD techniques.  In
addition, we devise a set of automated scripts to generate custom file
contexts and policies of a desired size.  Our complete source code,
scripts and installation guide are available
online\footnote{http://sourceforge.net/projects/selinuxoncbe/}.

A major portion of the computation involved in the validation of a
security context is string comparison operations.  These operations
are performed to match the context being labeled with the set of valid
contexts.  We offload these operations to the SPEs in the CBE
processor.  However, one of the downsides of using the SPE is that
data (the security context string in this case) required for the
operation has to be transfered using the DMA controller.  Typically
the SPE places a DMA request by providing the base address of the data
in main memory and the number of bytes.  Since a string is a
null-terminated character array of variable length, the SPE has to
place DMA requests one character at a time until it encounters the
null character.  This is clearly an inefficient strategy, since the
SPE keeps waiting till the entire string has been transferred to its
local cache.  Instead, each character that is transferred can be
compared with the corresponding character of the target string at the
same time as the next character is being read.  This is based on a
well-known technique called \emph{double buffering}.
Figure~\ref{figDMA} shows the control flow of this operation performed
by an SPE, where $mfc\textunderscore get$ is an API provided by the
CBE SDK to make DMA requests. The SPE is initialized with the base
address of the \emph{input} string which is the security context we
want to validate. Once the input string is transferred, the SPE then
uses double buffering to transfer \emph{str}, as shown in
Figure~\ref{figDMA}.  Here \emph{str} represents a particular valid
string from the list of valid contexts.

\begin{figure}
\centerline{\includegraphics[scale=0.45]{images/DMA.png}}
\caption{DMA double buffering technique for null terminated strings.}
\label{figDMA}
\vspace{-0.2cm}
\end{figure}

\subsection{Results}\label{results}

\begin{figure}
\centerline{\includegraphics[scale=0.65]{images/rules.png}}
\caption{Single core (PPE) performance of SELinux security context validation}
\label{figGraphRules}
\vspace{-0.01cm}
\end{figure}

Figure~\ref{figGraphRules} shows the running times of security context
validation, measured during the re-labeling process with increasing
numbers of rules in the security policy configuration.  We analyze the
difference in the rate of increase of running times for the two
curves.  The curve with \emph{minimal} AVC shows a considerable increase (by about
40\%) in run-time with number of rules in the range [0 - 2000],
whereas in the same range, the curve with \emph{optimal} AVC shows only a negligible
increase (by about 8\%) in running time.  However when the number of
rules is in the range [2500, 4000], the increase in running time is
considerably higher in both cases, which is 64\% and 112\%, for \emph{optimal}
and \emph{minimal} AVC sizes respectively.  An intuitive explanation for this
phenomenon is that the hit ratio of the AVC is generally quite high
with fewer number of policy rules.  This immense drop in performance
with \emph{minimal} AVC size also establishes the fact that security context
validations are computationally intensive.  In many modern day
systems, the number of rules in a security policy is well in excess of
5000, hence even with an \emph{optimal} AVC size, the performance overhead
of SELinux is significant.

Figure~\ref{figGraphTech} shows a histogram of the running times of
different techniques with a fixed number of 4000 rules in the security
policy.  The results show that when an \emph{optimal} AVC size is used, the running
time of the proposed SIMD techniques is higher than the single core
run-time.  This is counter to our intuition that using more cores
should generally improve performance.  Our investigation reveals the
cause to be an overhead in the SPE, due to: (1) initialization, which
is the act of loading an executable binary to the SPEs' local cache;
and (2) data transferred from main memory during execution.  We also
observe that techniques that use a busy-wait strategy perform
reasonably better, since the overhead due to repeated initialization
is considerably reduced.  For instance, the running times of $6U$ and
$6UBW$ are 38\% and 7\% higher than the respective single-core running
times, which goes to show the dominant impact of SPE initialization on
the overall performance.

\begin{figure}
\centerline{\includegraphics[scale=0.58]{images/techs.png}}
\caption{Comparison of running time of different techniques for SELinux security context validation (with 4000 rules in security policy)}
\label{figGraphTech}
\vspace{-0.05cm}
\end{figure}

The results with the \emph{minimal} AVC size show a stark reversal from those
observed earlier.  The running time of techniques that use multiple
cores is lower than single core run-time.  Though this is as expected,
the variation in the efficiency requires further insights.  We observe
that the sans busy wait strategies perform only slightly better than
single core, with an efficiency gain of about 8\% and 11\% for $3U$
and $6U$ respectively.  On the other hand, the techniques that use
busy wait strategy considerably outperform both single-core and their
SIMD counterparts, with a gain in efficiency of 32\% and 43\% for
$3UBW$ and $6UBW$ respectively.  Once again the $BW$ strategies show a
significant reduction in run-time since it virtually eliminates the
more prevalent overhead of SPE initialization.  Table~\ref{tab1} shows
the relative gain/loss in efficiency of each of the proposed
techniques when compared to the single core performance.

\begin{table}[ht]
\centering
\caption{Comparison of relative gain / loss in efficiency of proposed techniques against the single core (PPE) performance.}
\begin{tabular}{|c|c|c|c|c|} \hline
 &\textbf{3U}&\textbf{6U}&\textbf{3UBW}&\textbf{6UBW}\\ \hline
\textbf{Optimal AVC size}& -26\%& -38\%& -15\% & -7\%\\ \hline
\textbf{Minimal AVC size}& 8\%& 11\%& 32\% & 43\%\\ \hline
\end{tabular}
\label{tab1}
\end{table}

The key take-away from our results is that, security validations in
general can be modified for parallel executions, but the gain in
efficiency depends on the architecture of the software and the
hardware platform.  Our approach can be easily adapted to applications
with a similar security validation framework running on other
multicore platforms.

\section{Conclusion and Future Work}\label{conclusion}

Although there has been considerable research in the field of software
security, little has been done to improve performance and mitigate
related issues that may arise.  To deal with the demand of growing
security requirements, modern day operating systems provide
sophisticated in-built security features like Security Enhanced Linux
(SElinux).  These often result in unacceptably low system performance.
We hypothesized that security validations in general can be optimized
by exploiting their inherent data parallelism.  We ran several
experiments to evaluate the performance of SElinux when modified for
concurrent execution.  Our experimental setup consisted of
automatically generating security policies and measuring the running
time involved in SELinux security context validation, on a CBE
processor.  We obtained contrasting results wherein both gain and loss
in efficiency were observed, depending on the technique and system
configuration.  Our investigations revealed that performing
computations on the SPE came with a significant overhead in terms of
loading time and data transfers.  However, we found that the overhead
in SPEs can be overcome by utilizing them more often and for longer
duration.

\eat{ The performance comparison was made under two
different parameters - the number of rules in the policies and the
AVC size in SELinux security server module. Our
results showed that the use of optimal AVC size ensured the performance
overhead was within an acceptable limit, but this did not hold for
policies with a reasonably large number of rules. We also observed
contrasting results with the use of parallel execution techniques, in
fact a loss in performance when compared to single core performance with optimal AVC size. Whereas a gain in performance of up to 43\% was
measured with one of the multi-processor techniques with the minimal
AVC size. Our investigations revealed that Synergistic Processing Element
(SPE) execution had a significant overhead in terms of loading time
and data transfers. However, with the minimal AVC size, the SPEs were
utilized more often and long enough to overcome the delay due to
loading and data transfers and thereby register a net gain in
efficiency.}

In general, software applications designed for a uniprocessor system
cannot be easily optimized for parallel computing, and even when
modified the gain in efficiency may not be significant.  The problem
is especially prominent in security-related applications, since the
priority is robustness rather than efficiency.  We believe our work
will inspire future research in building applications that harness the
potential of multicore processors.

One obvious extension of our work is to apply the proposed techniques
to other security features / applications like TOMOYO Linux,
SMACK\footnote{http://schaufler-ca.com/}, etc., and compare their
performances.  Evaluating performance on different multicore
architectures like GPGPUs, modern PCs and mobile devices could give
greater insights into the effectiveness of the approach; e.g.,
performance analysis of
\textbf{SEAndroid}\footnote{http://selinuxproject.org/page/SEAndroid},
a MAC mechanism for Android platform.  Another interesting direction
could be to analyze the proposed techniques in distributed platforms
like Beowulf clusters and grid networks.

\bibliographystyle{IEEEtran}
\bibliography{references}
\end{document}
